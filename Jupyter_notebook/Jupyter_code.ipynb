{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch.tensor\n",
    "from model import datasets\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_dxy(skip_day):\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/BlankerL/DXY-COVID-19-Data/master/csv/DXYArea.csv\")\n",
    "    searchfor = ['外地来','明确地区','不明地区','未知地区','未知','人员','待明确']\n",
    "    data = data[~data['cityName'].str.contains('|'.join(searchfor))]\n",
    "    data = data[~data['provinceName'].str.contains('|'.join(['香港','台湾','澳门']))]\n",
    "    data = data[data['cityName'].groupby(data['cityName']).transform('size')>40]\n",
    "    data['updateTime']=pd.to_datetime(data['updateTime']).dt.date\n",
    "    grouped = data.sort_values('updateTime',ascending = False).groupby(['updateTime'])\n",
    "    i = 0\n",
    "    integrate = pd.DataFrame()\n",
    "    for name,group in grouped:\n",
    "        i +=1\n",
    "        set_group = group.drop_duplicates(['provinceName','cityName'])\n",
    "        set_group = set_group[['provinceName','cityName','city_confirmedCount','city_curedCount','city_deadCount']]\n",
    "        set_group.rename(columns={\"city_confirmedCount\": \"city_confirmedCount\"+' '+str(name), \n",
    "                                  \"city_curedCount\": \"city_curedCount\"+' '+str(name),\n",
    "                                  'city_deadCount': 'city_deadCount'+' '+str(name)}, inplace=True)\n",
    "        if i<=skip_day:\n",
    "            integrate = set_group\n",
    "        else:\n",
    "            integrate = integrate.merge(set_group, how = 'outer', on = ['provinceName','cityName'])\n",
    "    integrate.dropna(thresh=len(integrate.columns)*0.9, inplace = True)\n",
    "    integrate['ts']= integrate.iloc[:,2:].values.tolist()\n",
    "    integrate = integrate[['provinceName','cityName','ts']].reset_index(drop=True)\n",
    "    return integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data,window):\n",
    "    arraydata = []\n",
    "    for index, row in data.iterrows():\n",
    "        ts = np.diff(np.reshape(row.ts,(-1,3)),axis = 0)\n",
    "        ts = ts[~np.isnan(ts).any(axis=1),:]\n",
    "        for i in range(len(ts)-window+1):\n",
    "            seq = ts[i:i+window]\n",
    "            seq = np.nan_to_num(stats.zscore(seq, axis = 0))\n",
    "            arraydata.append(seq)\n",
    "    arraydata = torch.tensor(arraydata, dtype=torch.float)\n",
    "    #split or not\n",
    "    dataset = datasets(arraydata)\n",
    "    train_len = int(dataset.__len__()*0.8)\n",
    "    test_len = dataset.__len__()-train_len\n",
    "    train_data, test_data = random_split(dataset,[train_len,test_len])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, dtype=torch.float).requires_grad_()\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, dtype=torch.float).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class datasets(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[index][-1]\n",
    "        data_val = self.data[index] [:-1]\n",
    "        return data_val,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(train_data, test_data, num_epochs, batch_size=8, input_dim=3, hidden_dim=150, output_dim=3, seq_dim=7):\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    Mymodel = LSTMModel(input_dim, hidden_dim, 1, output_dim)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(Mymodel.parameters(), lr=0.01)\n",
    "    iters = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for data_val,target in train_loader:\n",
    "            # clean the previous gredient\n",
    "            optimizer.zero_grad()\n",
    "            outputs = Mymodel(data_val)\n",
    "            #calculate loss\n",
    "            loss = loss_function(outputs, target)\n",
    "            # using loss to calculate gredient, stored in model\n",
    "            loss.backward()\n",
    "            # using gredient to update model parameters\n",
    "            optimizer.step()\n",
    "            iters += 1\n",
    "            if iters % 300 ==0:\n",
    "                for test_val,test_target in test_loader:\n",
    "                    test_outputs = Mymodel(test_val)\n",
    "                    loss2 = loss_function(test_outputs, test_target)\n",
    "                print('Iteration: {}. TrainLoss: {}. TestLoss: {}'.format(iters, loss.item(), loss2.item()))\n",
    "                torch.save(Mymodel.state_dict(), 'trained_model_'+ str(iters) + '.pkl')\n",
    "    return Mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(provincename, cityname, modelpath, data):\n",
    "    Mymodel = LSTMModel(3, 150, 1, 3)\n",
    "    Mymodel.load_state_dict(torch.load(modelpath))\n",
    "    series = data.loc[(data[\"provinceName\"] == provincename) & (data[\"cityName\"] == cityname), \"ts\"].values.tolist()\n",
    "    series = np.reshape(series,(-1,3))\n",
    "    if np.isnan(series[-1][0]):\n",
    "        series = series[:-1]\n",
    "    diff_series = np.diff(series,axis = 0)\n",
    "    n = len(diff_series)\n",
    "    seq = []\n",
    "    predict_series = []\n",
    "    predict_series[:] = series[0:7]\n",
    "    store_diff = []\n",
    "    store_diff[:] = diff_series[0:7]\n",
    "    for i in range(n):\n",
    "        seq[:] = diff_series[i:i+7]\n",
    "        mean = np.mean(seq,axis = 0)\n",
    "        std = np.std(seq,axis = 0)\n",
    "        seq -= mean\n",
    "        seq /= std\n",
    "        tensor_seq = torch.tensor(np.nan_to_num([seq]), dtype=torch.float, requires_grad=False)\n",
    "        predictions = np.array(Mymodel(tensor_seq).tolist()[0])\n",
    "        real_diff = predictions * std + mean\n",
    "        store_diff = np.append(store_diff,[real_diff],axis = 0)\n",
    "        if i>=n-7:\n",
    "            diff_series = np.append(diff_series,[real_diff],axis = 0)\n",
    "            predict_series = np.append(predict_series,[np.array(list(map(sum,zip(predict_series[-1],real_diff))))],axis = 0)\n",
    "        else:\n",
    "            predict_series = np.append(predict_series,[np.array(list(map(sum,zip(series[i+6],real_diff))))],axis = 0)\n",
    "    return series, predict_series, provincename+cityname, store_diff, diff_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(origin,pred,title):\n",
    "    fontP = font_manager.FontProperties()\n",
    "    fontP.set_family('SimHei')\n",
    "    fontP.set_size(14)\n",
    "    \n",
    "    x1 = origin[:,0]\n",
    "    x2 = pred[:,0]\n",
    "    plt.plot(x1, label = \"True_value\")\n",
    "    plt.plot(x2, label = \"Predicted_value\")\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Infections')\n",
    "    plt.title(title,fontproperties=fontP)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ## custimized part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
